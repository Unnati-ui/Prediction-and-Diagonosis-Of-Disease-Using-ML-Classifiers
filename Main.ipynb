{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1624112401992,
     "user": {
      "displayName": "aditya agrawal",
      "photoUrl": "",
      "userId": "16186555788120472174"
     },
     "user_tz": -330
    },
    "id": "dlTgHJVGlWnD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1027,
     "status": "ok",
     "timestamp": 1624112063286,
     "user": {
      "displayName": "aditya agrawal",
      "photoUrl": "",
      "userId": "16186555788120472174"
     },
     "user_tz": -330
    },
    "id": "RxnU-5KHXv8a",
    "outputId": "7cbc5b49-9980-482c-aa38-bade7757ff90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:14:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.7792207792207793\n",
      "Accuracy: 0.8181818181818182\n",
      "Accuracy: 0.7402597402597403\n",
      "Ensemble Accuracy: 0.8051948051948052\n",
      "1 1 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "#reading data\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/harshtyagimdr/diabities_detection/master/diabaties.csv')\n",
    "\n",
    " \n",
    "\n",
    "feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness','DiabetesPedigreeFunction', 'Insulin', 'BMI', 'Age']\n",
    "\n",
    "predicted_class = ['Outcome']\n",
    "\n",
    " \n",
    "\n",
    "X = data[feature_columns].values\n",
    "\n",
    "y = data[predicted_class].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=10, stratify= y)\n",
    "\n",
    " \n",
    "\n",
    "#initializing models\n",
    "\n",
    "xgb = XGBClassifier(random_state=10 ,  n_estimators =  100)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=10 ,  n_estimators = 100)\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#training models\n",
    "\n",
    "xgb.fit(X_train, y_train.ravel())\n",
    "\n",
    "rf.fit(X_train, y_train.ravel())\n",
    "\n",
    "dt.fit(X_train, y_train.ravel())\n",
    "\n",
    "pickle.dump(rf,open('random_forest.pkl','wb'))\n",
    "pickle.dump(dt,open('decision_tree.pkl','wb'))\n",
    "pickle.dump(xgb,open('xgboost.pkl','wb'))\n",
    "\n",
    "\n",
    "#evaluating model performance\n",
    "\n",
    "xgb_acc = accuracy_score(y_test, xgb.predict(X_test))\n",
    "\n",
    "rf_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "\n",
    "dt_acc = accuracy_score(y_test, dt.predict(X_test))\n",
    "\n",
    "\n",
    "print(f'Accuracy: {xgb_acc}')\n",
    "\n",
    "print(f'Accuracy: {rf_acc}')\n",
    "\n",
    "print(f'Accuracy: {dt_acc}')\n",
    "\n",
    "\n",
    "\n",
    "#making predictions\n",
    "\n",
    "xgb_pred = xgb.predict(X_test[6].reshape(1, -1))[0]\n",
    "\n",
    "rf_pred = rf.predict(X_test[6].reshape(1, -1))[0]\n",
    "\n",
    "dt_pred = dt.predict(X_test[6].reshape(1, -1))[0]\n",
    "\n",
    "xgb_pred = xgb.predict(np.array([  6,    208,     72,     35,      0,     33.6,     0.171,  50,   ]).reshape(1, -1))[0]\n",
    "\n",
    "rf_pred = rf.predict([[  6,    208,     72,     35,      0,     33.6,     0.171,  50,   ]])[0]\n",
    "\n",
    "dt_pred = dt.predict([[  6,    208,     72,     35,      0,     33.6,     0.171,  50,   ]])[0]\n",
    "\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, mode([xgb.predict(X_test),rf.predict(X_test),dt.predict(X_test)])[0][0])\n",
    "\n",
    "\n",
    "print(f'Ensemble Accuracy: {acc}')\n",
    "\n",
    "print(xgb_pred,rf_pred,dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6117,
     "status": "ok",
     "timestamp": 1624107802490,
     "user": {
      "displayName": "aditya agrawal",
      "photoUrl": "",
      "userId": "16186555788120472174"
     },
     "user_tz": -330
    },
    "id": "ttf2E0VSXv8i",
    "outputId": "3ac3afff-b12b-470e-f26d-92c16d0dd5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Diabetes Pedigree fn is : 0.3725\n",
      "Max Decesion Tree Accuracy: 0.7922077922077922\n",
      "Min Decesion Tree Accuracy: 0.7272727272727273\n",
      "\n",
      "Max Random Forest Accuracy: 0.8181818181818182\n",
      "Min Random Forest Accuracy: 0.8181818181818182\n",
      "\n",
      "Max XGBoost Accuracy: 0.8441558441558441\n",
      "Min XGBoost Accuracy: 0.8441558441558441\n",
      "\n",
      "Max Ensemble Accuracy: 0.8571428571428571\n",
      "Min Ensemble Accuracy: 0.8571428571428571\n",
      "\n",
      "Max Accuracy: 0.8571428571428571\n",
      "Max Accuracy Technique: Ensemble\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "from statistics import median\n",
    "\n",
    "#reading data\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/harshtyagimdr/diabities_detection/master/diabaties.csv')\n",
    "\n",
    " \n",
    "\n",
    "feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "predicted_class = ['Outcome']\n",
    "\n",
    " \n",
    "\n",
    "X = data[feature_columns].values\n",
    "\n",
    "y = data[predicted_class].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=10, stratify= y)\n",
    "\n",
    "print(\"Median of Diabetes Pedigree fn is :\",median(data['DiabetesPedigreeFunction'].values))\n",
    "\n",
    "\n",
    "max_acc=0\n",
    "max_acc_technique=''\n",
    "max_dt_acc=0\n",
    "min_dt_acc=100\n",
    "\n",
    "max_rf_acc=0\n",
    "min_rf_acc=100\n",
    "max_xg_acc=0\n",
    "min_xg_acc=100\n",
    "\n",
    "max_ens_acc=0\n",
    "min_ens_acc=100\n",
    "\n",
    "for i in range(20):\n",
    "#initializing models\n",
    "\n",
    "  xgb = XGBClassifier(random_state=10 ,  n_estimators =  100)\n",
    "\n",
    "  rf = RandomForestClassifier(random_state=10 ,  n_estimators = 100)\n",
    "\n",
    "  dt = DecisionTreeClassifier(criterion='entropy', max_depth=8)\n",
    "\n",
    "  \n",
    "\n",
    "  #training models\n",
    "\n",
    "  xgb.fit(X_train, y_train.ravel())\n",
    "\n",
    "  rf.fit(X_train, y_train.ravel())\n",
    "\n",
    "  dt.fit(X_train, y_train.ravel())\n",
    "\n",
    "  \n",
    "\n",
    "  #evaluating model performance\n",
    "\n",
    "  xgb_acc = accuracy_score(y_test, xgb.predict(X_test))\n",
    "\n",
    "  rf_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "\n",
    "  dt_acc = accuracy_score(y_test, dt.predict(X_test))\n",
    "\n",
    "  #making predictions\n",
    "\n",
    "  xgb_pred = xgb.predict(X_test[6].reshape(1, -1))[0]\n",
    "\n",
    "  rf_pred = rf.predict(X_test[6].reshape(1, -1))[0]\n",
    "\n",
    "  dt_pred = dt.predict(X_test[6].reshape(1, -1))[0]\n",
    "\n",
    "\n",
    "  acc = accuracy_score(y_test, mode([xgb.predict(X_test),rf.predict(X_test),dt.predict(X_test)])[0][0])\n",
    "\n",
    "  max_ens_acc=max(max_ens_acc,acc)\n",
    "  min_ens_acc=min(min_ens_acc,acc)\n",
    "\n",
    "  max_dt_acc=max(max_dt_acc,dt_acc)\n",
    "  min_dt_acc=min(min_dt_acc,dt_acc)\n",
    "\n",
    "  max_rf_acc=max(max_rf_acc,rf_acc)\n",
    "  min_rf_acc=min(min_rf_acc,rf_acc)\n",
    "\n",
    "  max_xg_acc=max(max_xg_acc,xgb_acc)\n",
    "  min_xg_acc=min(min_xg_acc,xgb_acc)\n",
    "\n",
    "  max_acc=max([max_dt_acc,max_rf_acc,max_xg_acc,max_ens_acc])\n",
    "\n",
    "  if(max_acc==max_dt_acc):\n",
    "    max_acc_technique='Decesion Tree'\n",
    "  \n",
    "  if(max_acc==max_rf_acc):\n",
    "    max_acc_technique='Random Forest'\n",
    "\n",
    "  if(max_acc==max_xg_acc):\n",
    "    max_acc_technique='XGBoost'\n",
    "\n",
    "  if(max_acc==max_ens_acc):\n",
    "    max_acc_technique='Ensemble'\n",
    "\n",
    "print(f'Max Decesion Tree Accuracy: {max_dt_acc}')\n",
    "print(f'Min Decesion Tree Accuracy: {min_dt_acc}')\n",
    "print()\n",
    "print(f'Max Random Forest Accuracy: {max_rf_acc}')\n",
    "print(f'Min Random Forest Accuracy: {min_rf_acc}')\n",
    "print()\n",
    "print(f'Max XGBoost Accuracy: {max_xg_acc}')\n",
    "print(f'Min XGBoost Accuracy: {min_xg_acc}')\n",
    "print()\n",
    "print(f'Max Ensemble Accuracy: {max_ens_acc}')\n",
    "print(f'Min Ensemble Accuracy: {min_ens_acc}')\n",
    "print()\n",
    "print(f'Max Accuracy: {max_acc}')\n",
    "print(f'Max Accuracy Technique: {max_acc_technique}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Latest - Copy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
